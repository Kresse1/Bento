{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kresse1/Bento/blob/master/Project_PMML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UowRnRXBg2ck"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "(train_data, validation_data, test_data), info = tfds.load('cats_vs_dogs',\n",
        "                                                           split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\n",
        "                                                           with_info=True,\n",
        "                                                           as_supervised=True)\n",
        "\n",
        "# Get the label names\n",
        "label_names = info.features['label'].names\n",
        "\n",
        "# Preprocessing function: resize and normalize images\n",
        "def preprocess_image(image, label):\n",
        "    image = tf.image.resize(image, [224, 224])  # Resize to 224x224\n",
        "    image = tf.cast(image, tf.float32) / 255.0  # Normalize to [0, 1]\n",
        "    return image, label\n",
        "\n",
        "# Apply preprocessing and batch the data\n",
        "batch_size = 32\n",
        "train_data = train_data.map(preprocess_image).batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "validation_data = validation_data.map(preprocess_image).batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "test_data = test_data.map(preprocess_image).batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "# Display some sample images\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i, (image, label) in enumerate(train_data.unbatch().take(9)):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(image.numpy())\n",
        "    plt.title(label_names[label.numpy()])\n",
        "    plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "K6JGg6Taj7fb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow\n",
        "!pip install tensorflow_datasets\n",
        "!pip install matplotlib\n",
        "!pip install numpy"
      ],
      "metadata": {
        "id": "Gic3SmdGbiMI",
        "outputId": "c2d352a4-c8d5-4a74-ac78-9b025152e176",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.12.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.69.0)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: tensorflow_datasets in /usr/local/lib/python3.10/dist-packages (4.9.7)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (1.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (8.1.8)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (0.1.8)\n",
            "Requirement already satisfied: immutabledict in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (4.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (1.26.4)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (2.3)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (4.25.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (5.9.5)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (17.0.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (2.32.3)\n",
            "Requirement already satisfied: simple-parsing in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (0.1.6)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (1.13.1)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (2.5.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (0.10.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (4.67.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (1.17.0)\n",
            "Requirement already satisfied: array-record>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (0.6.0)\n",
            "Requirement already satisfied: etils>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow_datasets) (1.11.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow_datasets) (4.12.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow_datasets) (2024.10.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow_datasets) (6.5.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow_datasets) (3.21.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow_datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow_datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow_datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow_datasets) (2024.12.14)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from promise->tensorflow_datasets) (1.17.0)\n",
            "Requirement already satisfied: docstring-parser<1.0,>=0.15 in /usr/local/lib/python3.10/dist-packages (from simple-parsing->tensorflow_datasets) (0.16)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-metadata->tensorflow_datasets) (1.66.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "import random\n",
        "\n",
        "# Laden des vortrainierten Modells\n",
        "model = VGG16(weights='imagenet')\n",
        "\n",
        "def load_dataset():\n",
        "    \"\"\"Lädt das Cats vs Dogs Dataset von TensorFlow Datasets\"\"\"\n",
        "    dataset, info = tfds.load('cats_vs_dogs', with_info=True, as_supervised=True)\n",
        "    train_ds, validation_ds, test_ds = tfds.load(\n",
        "        'cats_vs_dogs',\n",
        "        split=['train[:70%]', 'train[70%:90%]', 'train[90%:]'],\n",
        "        as_supervised=True\n",
        "    )\n",
        "    return train_ds, validation_ds, test_ds\n",
        "\n",
        "def prepare_image(image, label):\n",
        "    \"\"\"Bereitet ein einzelnes Bild für VGG16 vor\"\"\"\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image = tf.image.resize(image, (224, 224))\n",
        "    image = tf.expand_dims(image, 0)\n",
        "    return image, label\n",
        "\n",
        "def create_adversarial_image(image, target_class, epsilon=20.0, iterations=10):\n",
        "    \"\"\"Erstellt ein adversariales Beispiel mit iterativem Angriff\"\"\"\n",
        "    image_tensor = tf.convert_to_tensor(image)\n",
        "    adv_image = tf.identity(image_tensor)\n",
        "\n",
        "    for _ in range(iterations):\n",
        "        with tf.GradientTape() as tape:\n",
        "            tape.watch(adv_image)\n",
        "            # Vorverarbeitung für VGG16\n",
        "            processed_image = preprocess_input(adv_image)\n",
        "            prediction = model(processed_image)\n",
        "            loss = -tf.keras.losses.SparseCategoricalCrossentropy()(\n",
        "                tf.constant([target_class]), prediction\n",
        "            )\n",
        "\n",
        "        # Gradient berechnen und anwenden\n",
        "        gradient = tape.gradient(loss, adv_image)\n",
        "        normalized_gradient = tf.sign(gradient)\n",
        "        adv_image = adv_image + epsilon * normalized_gradient / iterations\n",
        "\n",
        "        # Clip um sicherzustellen, dass wir im gültigen Bildbereich bleiben\n",
        "        adv_image = tf.clip_by_value(adv_image, 0, 255)\n",
        "\n",
        "    return adv_image\n",
        "\n",
        "def predict_class(image_array):\n",
        "    \"\"\"Vorhersage der Klasse mit VGG16\"\"\"\n",
        "    processed_image = preprocess_input(tf.cast(image_array, tf.float32))\n",
        "    predictions = model.predict(processed_image)\n",
        "    decoded_predictions = tf.keras.applications.vgg16.decode_predictions(predictions, top=3)[0]\n",
        "    return decoded_predictions[0]\n",
        "\n",
        "def process_dataset_samples(dataset, num_samples=3):\n",
        "    \"\"\"Verarbeitet Beispiele aus dem Dataset\"\"\"\n",
        "    results = []\n",
        "\n",
        "    # Sammle Beispiele für beide Klassen\n",
        "    cat_samples = []\n",
        "    dog_samples = []\n",
        "\n",
        "    for image, label in dataset:\n",
        "        if len(cat_samples) < num_samples and label == 0:  # Katze\n",
        "            cat_samples.append((image, label))\n",
        "        elif len(dog_samples) < num_samples and label == 1:  # Hund\n",
        "            dog_samples.append((image, label))\n",
        "\n",
        "        if len(cat_samples) >= num_samples and len(dog_samples) >= num_samples:\n",
        "            break\n",
        "\n",
        "    # Verarbeite alle Samples\n",
        "    for image, label in cat_samples + dog_samples:\n",
        "        # Bild vorbereiten\n",
        "        original_img, _ = prepare_image(image, label)\n",
        "\n",
        "        # Original klassifizieren\n",
        "        original_pred = predict_class(original_img)\n",
        "        print(f\"Original prediction: {original_pred}\")\n",
        "\n",
        "        # Target-Klasse festlegen (281 für Katze, 242 für Hund in VGG16)\n",
        "        target_class = 242 if label == 0 else 281  # 0 = Katze, 1 = Hund\n",
        "\n",
        "        # Adversariales Beispiel erstellen\n",
        "        adversarial_img = create_adversarial_image(original_img, target_class,\n",
        "                                                 epsilon=20.0, iterations=10)\n",
        "        adversarial_pred = predict_class(adversarial_img)\n",
        "        print(f\"Adversarial prediction: {adversarial_pred}\")\n",
        "\n",
        "        results.append({\n",
        "            'original_img': original_img,\n",
        "            'adversarial_img': adversarial_img,\n",
        "            'original_pred': original_pred,\n",
        "            'adversarial_pred': adversarial_pred,\n",
        "            'true_class': 'cat' if label == 0 else 'dog'\n",
        "        })\n",
        "\n",
        "    return results\n",
        "\n",
        "def plot_results(results):\n",
        "    \"\"\"Visualisiert die Ergebnisse\"\"\"\n",
        "    n = len(results)\n",
        "    fig, axes = plt.subplots(n, 2, figsize=(12, 4*n))\n",
        "\n",
        "    if n == 1:\n",
        "        axes = axes.reshape(1, -1)\n",
        "\n",
        "    for i, result in enumerate(results):\n",
        "        # Original Bild\n",
        "        orig_img = tf.cast(result['original_img'][0], tf.uint8).numpy()\n",
        "        axes[i, 0].imshow(orig_img)\n",
        "        axes[i, 0].set_title(f'Original ({result[\"true_class\"]})\\n'\n",
        "                            f'Klassifiziert als: {result[\"original_pred\"][1]}\\n'\n",
        "                            f'Konfidenz: {result[\"original_pred\"][2]:.2f}')\n",
        "\n",
        "        # Adversariales Bild\n",
        "        adv_img = tf.cast(result['adversarial_img'][0], tf.uint8).numpy()\n",
        "        axes[i, 1].imshow(adv_img)\n",
        "        axes[i, 1].set_title(f'Manipuliert ({result[\"true_class\"]})\\n'\n",
        "                            f'Klassifiziert als: {result[\"adversarial_pred\"][1]}\\n'\n",
        "                            f'Konfidenz: {result[\"adversarial_pred\"][2]:.2f}')\n",
        "\n",
        "        # Achsenbeschriftungen entfernen\n",
        "        axes[i, 0].axis('off')\n",
        "        axes[i, 1].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Hauptprogramm\n",
        "if __name__ == \"__main__\":\n",
        "    # Dataset laden\n",
        "    train_ds, validation_ds, test_ds = load_dataset()\n",
        "\n",
        "    print(\"Verarbeite Testdaten...\")\n",
        "    # Verwende Testdaten für die Demonstration\n",
        "    results = process_dataset_samples(test_ds, num_samples=3)\n",
        "\n",
        "    print(\"Zeige Ergebnisse...\")\n",
        "    plot_results(results)"
      ],
      "metadata": {
        "id": "2kH_omevbdrA",
        "outputId": "563efdef-aaeb-4888-ce01-d53dcd1896b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "\u001b[1m553467096/553467096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 0us/step\n",
            "Downloading and preparing dataset 786.67 MiB (download: 786.67 MiB, generated: 1.04 GiB, total: 1.81 GiB) to /root/tensorflow_datasets/cats_vs_dogs/4.0.1...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dl Completed...: 0 url [00:00, ? url/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8e8de365e4c74f56bb508baff85bb18e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dl Size...: 0 MiB [00:00, ? MiB/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "63d790db14ae4388b3076fd29d247cfd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating splits...:   0%|          | 0/1 [00:00<?, ? splits/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7e8819c731354b15808351040633371e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train examples...:   0%|          | 0/23262 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5a30a473a67c45aa964ba6f20a06967c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:1738 images were corrupted and were skipped\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Shuffling /root/tensorflow_datasets/cats_vs_dogs/incomplete.1OFBME_4.0.1/cats_vs_dogs-train.tfrecord*...:   0%…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "543d49eb92a548888a7fac9d63a4b79c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset cats_vs_dogs downloaded and prepared to /root/tensorflow_datasets/cats_vs_dogs/4.0.1. Subsequent calls will reuse this data.\n",
            "Verarbeite Testdaten...\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 884ms/step\n",
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
            "\u001b[1m35363/35363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Original prediction: ('n02123597', 'Siamese_cat', 0.99971825)\n"
          ]
        }
      ]
    }
  ]
}